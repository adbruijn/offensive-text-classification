{
  "__doc__": "Configuration",
  "bidirectional": false,
  "dropout": 0.1,
  "early_stopping_criteria": 20,
  "embedding_file": "data/GloVe/glove.twitter.27B.200d.txt",
  "filter_sizes": [
    2,
    3,
    4
  ],
  "hidden_dim": 170.0,
  "learning_rate": 0.000292,
  "max_seq_length": 45.0,
  "model_name": "LSTMAttention",
  "num_epochs": 500,
  "num_layers": 8.0,
  "output_dim": 2,
  "seed": 888974904,
  "test_bs": 32.0,
  "train_bs": 140.0,
  "use_mongo": false,
  "val_bs": 32.0,
  "warmup_proportion": 0.1
}